{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3710jvsc74a57bd00a54878ae54eb7b15455285fa4ed1f35c81237d60e683e02dbde7b2f8b800d16",
   "display_name": "Python 3.7.10 64-bit ('xaibench_tf': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "0a54878ae54eb7b15455285fa4ed1f35c81237d60e683e02dbde7b2f8b800d16"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/hawk31/graph-attribution/\")\n",
    "sys.path.append(\"/home/hawk31/xaibench_tf/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import collections\n",
    "import os\n",
    "from contextlib import nullcontext\n",
    "\n",
    "import dill\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sonnet as snt\n",
    "import tensorflow as tf\n",
    "from graph_attribution.experiments import GNN\n",
    "from graph_attribution.featurization import MolTensorizer, smiles_to_graphs_tuple\n",
    "from graph_attribution.graphnet_models import BlockType\n",
    "from graph_attribution.hparams import get_hparams\n",
    "from graph_attribution.tasks import BinaryClassificationTaskType\n",
    "from graph_attribution.templates import TargetType\n",
    "from graph_attribution.training import make_tf_opt_epoch_fn\n",
    "from tqdm import tqdm\n",
    "\n",
    "from xaibench.utils import LOG_PATH, MODELS_PATH\n",
    "\n",
    "GPUS = tf.config.list_physical_devices(\"GPU\")\n",
    "N_EPOCHS = 500\n",
    "N_LAYERS = 10\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "if GPUS:\n",
    "    tf.config.experimental.set_memory_growth(GPUS[0], True)\n",
    "    DEVICE = tf.device(\"/GPU:0\")\n",
    "else:\n",
    "    DEVICE = nullcontext()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(4326, 1)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/hawk31/graph-attribution/data/logic7/logic7_smiles.csv\")\n",
    "\n",
    "smiles, values = (\n",
    "    df[\"smiles\"].values,\n",
    "    df[\"label\"].values[:, np.newaxis],\n",
    ")\n",
    "\n",
    "tensorizer = MolTensorizer()\n",
    "graph_data = smiles_to_graphs_tuple(smiles, tensorizer)\n",
    "print(values.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = get_hparams(\n",
    "    {\n",
    "        \"block_type\": \"gcn\",\n",
    "        \"epochs\": N_EPOCHS,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"n_layers\": N_LAYERS,\n",
    "        \"task_type\": None,\n",
    "    }\n",
    ")\n",
    "task_act = BinaryClassificationTaskType().get_nn_activation_fn()\n",
    "task_loss = BinaryClassificationTaskType().get_nn_loss_fn()\n",
    "target_type = TargetType(\"globals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/500 [00:00<?, ?it/s]/home/hawk31/miniconda3/envs/xaibench_tf/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gcn/gcn_10/nodes_aggregator/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gcn/gcn_10/nodes_aggregator/GatherV2_grad/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradients/gcn/gcn_10/nodes_aggregator/GatherV2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/hawk31/miniconda3/envs/xaibench_tf/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gcn/gcn_9/nodes_aggregator/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gcn/gcn_9/nodes_aggregator/GatherV2_grad/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradients/gcn/gcn_9/nodes_aggregator/GatherV2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/hawk31/miniconda3/envs/xaibench_tf/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gcn/gcn_8/nodes_aggregator/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gcn/gcn_8/nodes_aggregator/GatherV2_grad/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradients/gcn/gcn_8/nodes_aggregator/GatherV2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/hawk31/miniconda3/envs/xaibench_tf/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gcn/gcn_7/nodes_aggregator/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gcn/gcn_7/nodes_aggregator/GatherV2_grad/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradients/gcn/gcn_7/nodes_aggregator/GatherV2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/hawk31/miniconda3/envs/xaibench_tf/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gcn/gcn_6/nodes_aggregator/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gcn/gcn_6/nodes_aggregator/GatherV2_grad/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradients/gcn/gcn_6/nodes_aggregator/GatherV2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/hawk31/miniconda3/envs/xaibench_tf/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gcn/gcn_5/nodes_aggregator/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gcn/gcn_5/nodes_aggregator/GatherV2_grad/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradients/gcn/gcn_5/nodes_aggregator/GatherV2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/hawk31/miniconda3/envs/xaibench_tf/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gcn/gcn_4/nodes_aggregator/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gcn/gcn_4/nodes_aggregator/GatherV2_grad/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradients/gcn/gcn_4/nodes_aggregator/GatherV2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/hawk31/miniconda3/envs/xaibench_tf/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gcn/gcn_3/nodes_aggregator/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gcn/gcn_3/nodes_aggregator/GatherV2_grad/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradients/gcn/gcn_3/nodes_aggregator/GatherV2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/hawk31/miniconda3/envs/xaibench_tf/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gcn/gcn_2/nodes_aggregator/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gcn/gcn_2/nodes_aggregator/GatherV2_grad/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradients/gcn/gcn_2/nodes_aggregator/GatherV2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "/home/hawk31/miniconda3/envs/xaibench_tf/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:437: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradients/gcn/gcn_1/nodes_aggregator/GatherV2_grad/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradients/gcn/gcn_1/nodes_aggregator/GatherV2_grad/Reshape:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"gradients/gcn/gcn_1/nodes_aggregator/GatherV2_grad/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"shape. This may consume a large amount of memory.\" % value)\n",
      "100%|██████████| 500/500 [25:49<00:00,  3.10s/it, bce=0.00224]\n"
     ]
    }
   ],
   "source": [
    "with DEVICE:\n",
    "    model = GNN(\n",
    "        node_size=hp.node_size,\n",
    "        edge_size=hp.edge_size,\n",
    "        global_size=hp.global_size,\n",
    "        y_output_size=1,\n",
    "        block_type=BlockType(hp.block_type),\n",
    "        activation=task_act,\n",
    "        target_type=target_type,\n",
    "        n_layers=hp.n_layers,\n",
    "    )\n",
    "    model(graph_data)  # one pass needed for init\n",
    "\n",
    "    optimizer = snt.optimizers.Adam(hp.learning_rate)\n",
    "\n",
    "    opt_one_epoch = make_tf_opt_epoch_fn(\n",
    "        graph_data, values, hp.batch_size, model, optimizer, task_loss\n",
    "    )\n",
    "\n",
    "    pbar = tqdm(range(hp.epochs))\n",
    "    metrics = collections.defaultdict(list)\n",
    "\n",
    "    for _ in pbar:\n",
    "        train_loss = opt_one_epoch(graph_data, values).numpy()\n",
    "        metrics[\"bce\"].append(train_loss)\n",
    "        y_hat = model(graph_data).numpy().squeeze()\n",
    "\n",
    "        pbar.set_postfix({key: values[-1] for key, values in metrics.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(values, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}